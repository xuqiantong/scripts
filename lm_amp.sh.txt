sbatch launch_8gpus.sh cv_adae512_sinpos_l8_h8_fc1024_dp0.3_ldp0_as_3 \
  --loss_type=adsm \
  --loss_adsm_input_size=512 \
  --loss_adsm_cutoffs=10000,50000 \
  --train_arch_file=/checkpoint/wav2letter/transfer_learning/transformer_lms/arch/adae512_sinpos_l8_h8_fc1024_dp0-3_ldp0.so \
  --train_optimizer=nag \
  --train_lr=1 \
  --train_warmup_updates=2000 \
  --train_lr_schedule=invsqrt \
  --train_momentum=0.9 \
  --train_weight_decay=0 \
  --data_train=/checkpoint/wav2letter/data/commonvoice/text/train.txt \
  --data_valid=/checkpoint/wav2letter/data/commonvoice/text/dev.txt \
  --dictionary=/checkpoint/wav2letter/transfer_learning/transformer_lms/dicts/cv.dict \
  --train_report_updates=300 \
  --train_save_updates=300 \
  --data_tokens_per_sample=256 \
  --data_batch_size=4


/checkpoint/wav2letter/transfer_learning/transformer_lms/arch/adae512_sinpos_l8_h8_fc1024_dp0-3_ldp0.cpp

/checkpoint/wav2letter/transfer_learning/transformer_lms
models/cv_adae512_sinpos_l8_h8_fc1024_dp0.3_ldp0_as_3

----------

make -j40 && rm -rf /tmp/lm/ && \
mpirun -n 8 /private/home/qiantong/fl_org/flashlight_master/build/bin/lm/fl_lm_train \
  --logtostderr=true \
  --distributed_enable=true \
  --exp_rundir=/tmp/lm \
  --exp_model_name=lm \
  --data_dir= \
  --data_sample_break_mode=none \
  --data_tokens_per_sample=3072 \
  --train_max_grad_norm=0.1 \
  --train_report_updates=1000 \
  --train_save_updates=10000 \
  --train_warmup_init_lr=1e-7 \
  --loss_type=adsm \
  --loss_adsm_input_size=512 \
  --loss_adsm_cutoffs=10000,50000 \
  --train_arch_file=/checkpoint/wav2letter/transfer_learning/transformer_lms/arch/adae512_sinpos_l8_h8_fc1024_dp0-3_ldp0.so \
  --train_optimizer=nag \
  --train_lr=1 \
  --train_warmup_updates=2000 \
  --train_lr_schedule=invsqrt \
  --train_momentum=0.9 \
  --train_weight_decay=0 \
  --data_train=/checkpoint/wav2letter/data/commonvoice/text/train.txt \
  --data_valid=/checkpoint/wav2letter/data/commonvoice/text/dev.txt \
  --dictionary=/checkpoint/wav2letter/transfer_learning/transformer_lms/dicts/cv.dict \
  --train_report_updates=300 \
  --train_save_updates=300 \
  --data_tokens_per_sample=256 \
  --data_batch_size=4 \
  --fl_amp_use_mixed_precision=false


I0401 21:42:49.843291 1120915 Trainer.cpp:271] [epoch=1 batch=1200/4843] | Run Time: 00:00:11 | Batch Time(ms): 38.45 | Sample Time(ms): 0.06 | Forward Time(ms): 13.16 | Criterion Forward Time(ms): 2.94 | Backward Time(ms): 18.97 | Optimization Time(ms): 6.20 | Throughput (Token/Sec): 26526.83 | Learning Rate 0.599500 | Loss: 6.78 PPL: 878.85 | Valid Loss: 6.44 Valid PPL: 626.05


make -j40 && rm -rf /tmp/lm/ && \
mpirun -n 8 /private/home/qiantong/fl_org/flashlight_master/build/bin/lm/fl_lm_train \
  --logtostderr=true \
  --distributed_enable=true \
  --exp_rundir=/tmp/lm \
  --exp_model_name=lm \
  --data_dir= \
  --data_sample_break_mode=none \
  --data_tokens_per_sample=3072 \
  --train_max_grad_norm=0.1 \
  --train_report_updates=1000 \
  --train_save_updates=10000 \
  --train_warmup_init_lr=1e-7 \
  --loss_type=adsm \
  --loss_adsm_input_size=512 \
  --loss_adsm_cutoffs=10000,50000 \
  --train_arch_file=/checkpoint/wav2letter/transfer_learning/transformer_lms/arch/adae512_sinpos_l8_h8_fc1024_dp0-3_ldp0.so \
  --train_optimizer=nag \
  --train_lr=1 \
  --train_warmup_updates=2000 \
  --train_lr_schedule=invsqrt \
  --train_momentum=0.9 \
  --train_weight_decay=0 \
  --data_train=/checkpoint/wav2letter/data/commonvoice/text/train.txt \
  --data_valid=/checkpoint/wav2letter/data/commonvoice/text/dev.txt \
  --dictionary=/checkpoint/wav2letter/transfer_learning/transformer_lms/dicts/cv.dict \
  --train_report_updates=300 \
  --train_save_updates=300 \
  --data_tokens_per_sample=256 \
  --data_batch_size=4 \
  --fl_amp_use_mixed_precision=true


make -j40 && rm -rf /tmp/lm/ && \
/private/home/qiantong/fl_org/flashlight_master/build/bin/lm/fl_lm_train \
  --logtostderr=true \
  --distributed_enable=true \
  --exp_rundir=/tmp/lm \
  --exp_model_name=lm \
  --data_dir= \
  --data_sample_break_mode=none \
  --data_tokens_per_sample=3072 \
  --train_max_grad_norm=0.1 \
  --train_report_updates=1000 \
  --train_save_updates=10000 \
  --train_warmup_init_lr=1e-7 \
  --loss_type=adsm \
  --loss_adsm_input_size=512 \
  --loss_adsm_cutoffs=10000,50000 \
  --train_arch_file=/checkpoint/wav2letter/transfer_learning/transformer_lms/arch/adae512_sinpos_l8_h8_fc1024_dp0-3_ldp0.so \
  --train_optimizer=nag \
  --train_lr=1 \
  --train_warmup_updates=2000 \
  --train_lr_schedule=invsqrt \
  --train_momentum=0.9 \
  --train_weight_decay=0 \
  --data_train=/checkpoint/wav2letter/data/commonvoice/text/train.txt \
  --data_valid=/checkpoint/wav2letter/data/commonvoice/text/dev.txt \
  --dictionary=/checkpoint/wav2letter/transfer_learning/transformer_lms/dicts/cv.dict \
  --train_report_updates=300 \
  --train_save_updates=300 \
  --data_tokens_per_sample=256 \
  --data_batch_size=4 \
  --fl_amp_use_mixed_precision=true \
  --fl_optim_mode=O1

